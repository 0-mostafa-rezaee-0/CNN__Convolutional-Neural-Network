{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:2.5em; font-weight:bold; text-align:center; margin-top:20px;\">CNN-Based MNIST Digit Recognition</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center; margin-bottom:30px;\">A comprehensive project for digit recognition using Convolutional Neural Networks</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates the implementation of a Convolutional Neural Network (CNN) for handwritten digit recognition using the MNIST dataset. The MNIST dataset consists of 70,000 grayscale images of handwritten digits (0-9), each 28Ã—28 pixels in size.\n",
    "\n",
    "We'll go through the entire process from data preparation to model evaluation, including:\n",
    "- Loading and preprocessing the MNIST dataset\n",
    "- Building a CNN architecture\n",
    "- Training the model\n",
    "- Evaluating model performance\n",
    "- Visualizing results and feature maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by importing the necessary libraries and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Create directories for outputs if they don't exist\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll load the MNIST dataset and prepare it for training our CNN model.\n",
    "\n",
    "We need to perform the following data preparation steps:\n",
    "1. Load the MNIST dataset\n",
    "2. Normalize pixel values to the range [0, 1]\n",
    "3. Reshape the data to include a channel dimension (28x28x1)\n",
    "4. Convert labels to one-hot encoded vectors\n",
    "5. Split the data into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(val_split=0.1, random_seed=42):\n",
    "    # Load MNIST data from keras\n",
    "    print(\"Loading MNIST dataset...\")\n",
    "    (x_train_full, y_train_full), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    # Normalize pixel values to [0, 1]\n",
    "    x_train_full = x_train_full.astype('float32') / 255.0\n",
    "    x_test = x_test.astype('float32') / 255.0\n",
    "    \n",
    "    # Reshape to include channel dimension (28x28x1)\n",
    "    x_train_full = x_train_full.reshape(-1, 28, 28, 1)\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "    \n",
    "    # Convert class vectors to binary class matrices (one-hot encoding)\n",
    "    y_train_full = to_categorical(y_train_full, 10)\n",
    "    y_test = to_categorical(y_test, 10)\n",
    "    \n",
    "    # Split training data into train and validation sets\n",
    "    np.random.seed(random_seed)\n",
    "    indices = np.random.permutation(len(x_train_full))\n",
    "    val_size = int(len(x_train_full) * val_split)\n",
    "    train_indices = indices[val_size:]\n",
    "    val_indices = indices[:val_size]\n",
    "    \n",
    "    x_val = x_train_full[val_indices]\n",
    "    y_val = y_train_full[val_indices]\n",
    "    x_train = x_train_full[train_indices]\n",
    "    y_train = y_train_full[train_indices]\n",
    "    \n",
    "    print(f\"Training set: {x_train.shape[0]} samples\")\n",
    "    print(f\"Validation set: {x_val.shape[0]} samples\")\n",
    "    print(f\"Test set: {x_test.shape[0]} samples\")\n",
    "    \n",
    "    return (x_train, y_train), (x_val, y_val), (x_test, y_test)\n",
    "\n",
    "# Load and preprocess data\n",
    "(x_train, y_train), (x_val, y_val), (x_test, y_test) = load_and_preprocess_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some examples from the MNIST dataset to get a better understanding of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_mnist_samples(x_data, y_data, num_samples=10):\n",
    "    \"\"\"Visualize sample images from the MNIST dataset.\"\"\"\n",
    "    plt.figure(figsize=(15, 2))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        \n",
    "        # Get the image and reshape it to 28x28\n",
    "        img = x_data[i].reshape(28, 28)\n",
    "        \n",
    "        # Get the label (assuming one-hot encoded)\n",
    "        label = np.argmax(y_data[i])\n",
    "        \n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"Digit: {label}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/mnist_samples.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize MNIST samples\n",
    "visualize_mnist_samples(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data augmentation is a technique to artificially increase the size of the training dataset by applying various transformations to the original images. This helps improve model generalization and reduces overfitting.\n",
    "\n",
    "Let's define a data augmentation pipeline for our MNIST images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_data_augmentation():\n",
    "    \"\"\"Create a data augmentation pipeline for MNIST dataset.\"\"\"\n",
    "    data_augmentation = models.Sequential([\n",
    "        layers.experimental.preprocessing.RandomRotation(0.1),\n",
    "        layers.experimental.preprocessing.RandomZoom(0.1),\n",
    "        layers.experimental.preprocessing.RandomTranslation(0.1, 0.1)\n",
    "    ])\n",
    "    return data_augmentation\n",
    "\n",
    "# Create data augmentation pipeline\n",
    "data_augmentation = create_data_augmentation()\n",
    "\n",
    "# Visualize augmented samples\n",
    "plt.figure(figsize=(15, 4))\n",
    "for i in range(5):\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    img = x_train[i].reshape(28, 28, 1)\n",
    "    plt.imshow(img.reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Original {np.argmax(y_train[i])}\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    ax = plt.subplot(2, 5, i+6)\n",
    "    augmented_img = data_augmentation(tf.expand_dims(img, 0))[0]\n",
    "    plt.imshow(augmented_img.numpy().reshape(28, 28), cmap='gray')\n",
    "    plt.title(f\"Augmented {np.argmax(y_train[i])}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/augmented_samples.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. CNN Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional Neural Networks (CNNs) are particularly well-suited for image classification tasks. They use convolutional layers to automatically detect features in images, followed by pooling layers to reduce dimensionality while preserving important information.\n",
    "\n",
    "For our MNIST model, we'll implement a simple CNN architecture with the following components:\n",
    "- Convolutional layers with ReLU activation\n",
    "- Max pooling layers\n",
    "- Dropout for regularization\n",
    "- Batch normalization for faster convergence\n",
    "- Dense layers for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_simple_cnn():\n",
    "    \"\"\"Create a simple CNN model for MNIST classification.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Input layer (28x28x1)\n",
    "        layers.Input(shape=(28, 28, 1)),\n",
    "        \n",
    "        # First convolutional block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the CNN model\n",
    "model = create_simple_cnn()\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Model Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined our model architecture, we need to compile it with an appropriate loss function, optimizer, and evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    \"\"\"Compile the model with appropriate loss, optimizer, and metrics.\"\"\"\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Compile the model\n",
    "model = compile_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define callbacks to monitor and improve the training process:\n",
    "- ModelCheckpoint: Save the best model based on validation accuracy\n",
    "- EarlyStopping: Stop training if validation loss doesn't improve\n",
    "- ReduceLROnPlateau: Reduce learning rate when metrics plateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_callbacks():\n",
    "    \"\"\"Create callbacks for model training.\"\"\"\n",
    "    checkpoint_path = \"models/mnist_cnn_best.h5\"\n",
    "    \n",
    "    callbacks_list = [\n",
    "        # Save the best model\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_path,\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "        \n",
    "        # Early stopping\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=10,\n",
    "            verbose=1,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        \n",
    "        # Reduce learning rate\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    return callbacks_list\n",
    "\n",
    "# Create callbacks\n",
    "callbacks = create_callbacks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Training Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, model, and callbacks ready, let's train the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, x_train, y_train, x_val, y_val, callbacks, batch_size=128, epochs=20):\n",
    "    \"\"\"Train the model and return history.\"\"\"\n",
    "    print(\"Starting model training...\")\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_val, y_val),\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Save the final model\n",
    "    model.save(\"models/mnist_cnn_final.h5\")\n",
    "    print(\"Model training completed.\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train the model\n",
    "history = train_model(model, x_train, y_train, x_val, y_val, callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Training Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the training process by plotting accuracy and loss curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training and validation accuracy/loss.\"\"\"\n",
    "    # Create a figure with 2 subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot training & validation accuracy\n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend(loc='lower right')\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    # Plot training & validation loss\n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/training_history.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model on the test dataset to see how well it generalizes to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def evaluate_model(model, x_test, y_test):\n",
    "    \"\"\"Evaluate the model on test data and return metrics.\"\"\"\n",
    "    print(\"Evaluating model on test data...\")\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    print(f\"Test Loss: {test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "    \n",
    "    return test_loss, test_accuracy\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = evaluate_model(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a useful tool to visualize the performance of a classification model. It shows the counts of true positives, false positives, true negatives, and false negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model, x_test, y_test):\n",
    "    \"\"\"Plot confusion matrix for model evaluation.\"\"\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import seaborn as sns\n",
    "    \n",
    "    # Get predictions\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_true_classes = np.argmax(y_test, axis=1)\n",
    "    \n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=range(10), yticklabels=range(10))\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Digit')\n",
    "    plt.xlabel('Predicted Digit')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/confusion_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate and print the classification report\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true_classes, y_pred_classes, digits=4))\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Visualizing Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize some of the model's predictions on test images to get a better understanding of how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_predictions(model, x_test, y_test, num_samples=10):\n",
    "    \"\"\"Visualize model predictions on test samples.\"\"\"\n",
    "    # Get random sample indices\n",
    "    indices = np.random.choice(range(len(x_test)), size=num_samples, replace=False)\n",
    "    \n",
    "    # Get predictions\n",
    "    predictions = model.predict(x_test[indices])\n",
    "    pred_classes = np.argmax(predictions, axis=1)\n",
    "    true_classes = np.argmax(y_test[indices], axis=1)\n",
    "    \n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(15, 4))\n",
    "    \n",
    "    # Plot each sample\n",
    "    for i, idx in enumerate(range(num_samples)):\n",
    "        plt.subplot(2, 5, i+1)\n",
    "        \n",
    "        # Get the image and reshape it\n",
    "        img = x_test[indices[idx]].reshape(28, 28)\n",
    "        \n",
    "        # Get prediction and true label\n",
    "        pred = pred_classes[idx]\n",
    "        true = true_classes[idx]\n",
    "        \n",
    "        # Set title color based on prediction correctness\n",
    "        title_color = 'green' if pred == true else 'red'\n",
    "        \n",
    "        # Display the image\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.title(f\"True: {true}, Pred: {pred}\", color=title_color)\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('figures/prediction_samples.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# Visualize predictions\n",
    "visualize_predictions(model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Feature Map Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature maps show the activations of different convolutional filters when an image is passed through the network. They can provide insights into what features or patterns each filter is detecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_feature_maps(model, x_test):\n",
    "    \"\"\"Visualize feature maps (activations) for a test image.\"\"\"\n",
    "    # Get a test image\n",
    "    test_img = x_test[0:1]  # Add batch dimension\n",
    "    \n",
    "    # Create a model that outputs feature maps from all conv layers\n",
    "    layer_outputs = [layer.output for layer in model.layers if 'conv' in layer.name.lower()]\n",
    "    activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "    \n",
    "    # Get activations\n",
    "    activations = activation_model.predict(test_img)\n",
    "    \n",
    "    # Plot the input image\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(test_img[0, :, :, 0], cmap='gray')\n",
    "    plt.title('Input Image')\n",
    "    plt.axis('off')\n",
    "    plt.savefig('figures/input_image.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot feature maps for each convolutional layer\n",
    "    for i, layer_activation in enumerate(activations):\n",
    "        layer_name = [layer.name for layer in model.layers if 'conv' in layer.name.lower()][i]\n",
    "        n_features = layer_activation.shape[-1]  # Number of features in the feature map\n",
    "        \n",
    "        # Calculate grid size\n",
    "        size = layer_activation.shape[1]\n",
    "        n_cols = min(8, n_features)\n",
    "        n_rows = int(np.ceil(n_features / n_cols))\n",
    "        \n",
    "        # Create figure\n",
    "        fig = plt.figure(figsize=(15, n_rows * 2))\n",
    "        fig.suptitle(f'Feature Maps - {layer_name} (Layer {i+1})', fontsize=14)\n",
    "        \n",
    "        # Plot each feature map\n",
    "        for j in range(n_features):\n",
    "            plt.subplot(n_rows, n_cols, j + 1)\n",
    "            plt.imshow(layer_activation[0, :, :, j], cmap='viridis')\n",
    "            plt.title(f'Filter {j}')\n",
    "            plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "        plt.savefig(f'figures/feature_maps_layer_{i+1}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "# Visualize feature maps\n",
    "visualize_feature_maps(model, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Model Improvement Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several strategies we can use to potentially improve our CNN model for MNIST digit recognition:\n",
    "\n",
    "1. **Deeper Architecture**: Add more convolutional layers to capture more complex features.\n",
    "2. **Learning Rate Scheduling**: Implement a learning rate schedule to fine-tune the training process.\n",
    "3. **More Data Augmentation**: Add additional augmentation techniques to increase the diversity of training data.\n",
    "4. **Ensemble Methods**: Combine multiple models to improve overall performance.\n",
    "5. **Transfer Learning**: Use pre-trained models and fine-tune them for our task.\n",
    "\n",
    "Let's implement a slightly more complex model architecture and compare its performance with our original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_deeper_cnn():\n",
    "    \"\"\"Create a deeper CNN model for MNIST classification.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        # Input layer (28x28x1)\n",
    "        layers.Input(shape=(28, 28, 1)),\n",
    "        \n",
    "        # First convolutional block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Second convolutional block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Third convolutional block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        \n",
    "        # Flatten and dense layers\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create and compile the deeper model\n",
    "deeper_model = create_deeper_cnn()\n",
    "deeper_model = compile_model(deeper_model)\n",
    "deeper_model.summary()\n",
    "\n",
    "# Train the deeper model (optional - uncomment to run)\n",
    "# deeper_history = train_model(deeper_model, x_train, y_train, x_val, y_val, callbacks)\n",
    "\n",
    "# Evaluate the deeper model (optional - uncomment to run)\n",
    "# deeper_test_loss, deeper_test_accuracy = evaluate_model(deeper_model, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we've demonstrated the implementation of a Convolutional Neural Network (CNN) for digit recognition using the MNIST dataset. We've covered the entire machine learning pipeline:\n",
    "\n",
    "1. **Data Preparation**: Loading, preprocessing, and visualizing the MNIST dataset\n",
    "2. **Model Architecture**: Designing and implementing a CNN architecture for digit recognition\n",
    "3. **Model Training**: Training the model with appropriate callbacks and monitoring\n",
    "4. **Model Evaluation**: Evaluating the model's performance on test data\n",
    "5. **Visualization**: Visualizing feature maps to understand what the CNN learns\n",
    "6. **Improvement Strategies**: Discussing ways to improve model performance\n",
    "\n",
    "Our CNN model achieved high accuracy on the MNIST dataset, demonstrating the effectiveness of convolutional neural networks for image classification tasks. The visualizations provided insights into how the model processes the input images and what features it extracts at different levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Further Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some resources for further learning about CNNs and digit recognition:\n",
    "\n",
    "1. **Books**:\n",
    "   - \"Deep Learning\" by Ian Goodfellow, Yoshua Bengio, and Aaron Courville\n",
    "   - \"Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow\" by AurÃ©lien GÃ©ron\n",
    "\n",
    "2. **Online Courses**:\n",
    "   - Coursera's Deep Learning Specialization by Andrew Ng\n",
    "   - Fast.ai's Practical Deep Learning for Coders\n",
    "\n",
    "3. **Research Papers**:\n",
    "   - \"Gradient-Based Learning Applied to Document Recognition\" by Yann LeCun et al.\n",
    "   - \"ImageNet Classification with Deep Convolutional Neural Networks\" by Alex Krizhevsky et al.\n",
    "\n",
    "4. **Websites and Blogs**:\n",
    "   - TensorFlow and Keras official documentation\n",
    "   - Distill.pub for visualizations and explanations of deep learning concepts\n",
    "   - PyImageSearch for practical computer vision tutorials"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
