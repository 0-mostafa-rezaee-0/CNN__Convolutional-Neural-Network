{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">MNIST Data Exploration & Visualization</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we'll explore the MNIST dataset of handwritten digits. We'll visualize the data, examine its characteristics, and prepare it for training a Convolutional Neural Network (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Set Display Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Configure visualization settings\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['axes.grid'] = True\n",
    "plt.rcParams['grid.alpha'] = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dataset Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(f\"Training data shape: {x_train.shape}\")\n",
    "print(f\"Training labels shape: {y_train.shape}\")\n",
    "print(f\"Test data shape: {x_test.shape}\")\n",
    "print(f\"Test labels shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Initial Data Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Display dataset information\n",
    "print(\"Dataset Information:\")\n",
    "print(f\"Total training images: {len(x_train)}\")\n",
    "print(f\"Total test images: {len(x_test)}\")\n",
    "print(f\"Image dimensions: {x_train[0].shape}\")\n",
    "print(f\"Data type: {x_train.dtype}\")\n",
    "print(f\"Min pixel value: {x_train.min()}\")\n",
    "print(f\"Max pixel value: {x_train.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Basic Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Display Sample Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Display a grid of sample images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    # Find the first image of digit i\n",
    "    idx = np.where(y_train == i)[0][0]\n",
    "    \n",
    "    # Display the image\n",
    "    axes[i].imshow(x_train[idx], cmap='gray')\n",
    "    axes[i].set_title(f\"Digit: {i}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Sample Images from Each Digit Class\", y=1.05, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Pixel Intensity Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the distribution of pixel intensities\n",
    "pixel_values = x_train.reshape(-1)  # Flatten all images\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(pixel_values, bins=50, color='skyblue', alpha=0.7)\n",
    "plt.title(\"Distribution of Pixel Intensities\", fontsize=14)\n",
    "plt.xlabel(\"Pixel Value\", fontsize=12)\n",
    "plt.ylabel(\"Frequency\", fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Print statistics about pixel values\n",
    "print(f\"Mean pixel value: {np.mean(pixel_values):.2f}\")\n",
    "print(f\"Median pixel value: {np.median(pixel_values)}\")\n",
    "print(f\"Standard deviation: {np.std(pixel_values):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Analyze class distribution\n",
    "unique_labels, counts = np.unique(y_train, return_counts=True)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(unique_labels, counts, color='skyblue')\n",
    "plt.title(\"Class Distribution in Training Set\", fontsize=14)\n",
    "plt.xlabel(\"Digit Class\", fontsize=12)\n",
    "plt.ylabel(\"Number of Images\", fontsize=12)\n",
    "plt.xticks(unique_labels)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Print class statistics\n",
    "for digit, count in zip(unique_labels, counts):\n",
    "    print(f\"Digit {digit}: {count} images ({count/len(y_train)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Class Balance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize class balance as a pie chart\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.pie(counts, labels=unique_labels, autopct='%1.1f%%', \n",
    "        shadow=True, startangle=90, colors=plt.cm.tab10.colors)\n",
    "plt.axis('equal')\n",
    "plt.title(\"Class Distribution in Training Set\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Image Characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Average Digit Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate and display the average image for each digit class\n",
    "avg_digits = np.zeros((10, 28, 28))\n",
    "\n",
    "for i in range(10):\n",
    "    # Find all images of digit i\n",
    "    indices = np.where(y_train == i)[0]\n",
    "    avg_digits[i] = np.mean(x_train[indices], axis=0)\n",
    "\n",
    "# Display average images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    axes[i].imshow(avg_digits[i], cmap='viridis')\n",
    "    axes[i].set_title(f\"Average Digit: {i}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Average Image for Each Digit Class\", y=1.05, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Digit Variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate standard deviation of pixel values for each digit class\n",
    "std_digits = np.zeros((10, 28, 28))\n",
    "\n",
    "for i in range(10):\n",
    "    indices = np.where(y_train == i)[0]\n",
    "    std_digits[i] = np.std(x_train[indices], axis=0)\n",
    "\n",
    "# Display standard deviation images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    im = axes[i].imshow(std_digits[i], cmap='plasma')\n",
    "    axes[i].set_title(f\"Digit {i} Variability\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(right=0.9)\n",
    "cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "fig.colorbar(im, cax=cbar_ax)\n",
    "plt.suptitle(\"Pixel Variability for Each Digit Class\", y=1.05, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Exploring Digit Variations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1. Multiple Examples Per Digit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2. Digit Morphology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Display multiple examples for each digit\n",
    "samples_per_digit = 5\n",
    "fig, axes = plt.subplots(10, samples_per_digit, figsize=(12, 16))\n",
    "\n",
    "for digit in range(10):\n",
    "    # Find indices of this digit\n",
    "    indices = np.where(y_train == digit)[0]\n",
    "    # Randomly select samples_per_digit examples\n",
    "    selected_indices = np.random.choice(indices, samples_per_digit, replace=False)\n",
    "    \n",
    "    for i, idx in enumerate(selected_indices):\n",
    "        axes[digit, i].imshow(x_train[idx], cmap='gray')\n",
    "        axes[digit, i].axis('off')\n",
    "    \n",
    "    # Add label for the digit on the left\n",
    "    axes[digit, 0].set_ylabel(f\"Digit {digit}\", rotation=0, labelpad=40, \n",
    "                              fontsize=14, ha='right', va='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Variations Within Each Digit Class\", y=1.01, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate and display average contours for each digit\n",
    "def get_contour(img, threshold=50):\n",
    "    \"\"\"Extract contour from digit image.\"\"\"\n",
    "    binary = (img > threshold).astype(np.uint8)\n",
    "    from skimage import measure\n",
    "    contours = measure.find_contours(binary, 0.5)\n",
    "    return contours[0] if contours else None\n",
    "\n",
    "# Display a random digit with its contour\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(10):\n",
    "    # Select a random image of digit i\n",
    "    idx = np.random.choice(np.where(y_train == i)[0])\n",
    "    img = x_train[idx]\n",
    "    \n",
    "    # Plot the image\n",
    "    axes[i].imshow(img, cmap='gray')\n",
    "    \n",
    "    # Extract and plot contour\n",
    "    contour = get_contour(img)\n",
    "    if contour is not None:\n",
    "        axes[i].plot(contour[:, 1], contour[:, 0], 'r', linewidth=2)\n",
    "    \n",
    "    axes[i].set_title(f\"Digit {i} with Contour\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Digit Contours\", y=1.05, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Use t-SNE to visualize the high-dimensional data in 2D\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Sample a subset of images for t-SNE (it's computationally intensive)\n",
    "n_samples = 2000\n",
    "random_indices = np.random.choice(len(x_train), n_samples, replace=False)\n",
    "sampled_images = x_train[random_indices].reshape(n_samples, -1)\n",
    "sampled_labels = y_train[random_indices]\n",
    "\n",
    "# Apply t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_results = tsne.fit_transform(sampled_images)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 10))\n",
    "scatter = plt.scatter(tsne_results[:, 0], tsne_results[:, 1], \n",
    "                     c=sampled_labels, cmap='tab10', alpha=0.6, s=30)\n",
    "plt.colorbar(scatter, label='Digit Class')\n",
    "plt.title('t-SNE Visualization of MNIST Digits', fontsize=14)\n",
    "plt.xlabel('t-SNE Feature 1', fontsize=12)\n",
    "plt.ylabel('t-SNE Feature 2', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Apply PCA to visualize the data\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(x_train.reshape(len(x_train), -1))\n",
    "\n",
    "# Create a dataframe for easier plotting\n",
    "pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])\n",
    "pca_df['digit'] = y_train\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='digit', data=pca_df, \n",
    "                palette='tab10', alpha=0.6, s=30)\n",
    "plt.title('PCA Visualization of MNIST Digits', fontsize=14)\n",
    "plt.xlabel('Principal Component 1', fontsize=12)\n",
    "plt.ylabel('Principal Component 2', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(title='Digit')\n",
    "plt.show()\n",
    "\n",
    "# Print variance explained by the first two principal components\n",
    "print(f\"Variance explained by PC1: {pca.explained_variance_ratio_[0]:.4f}\")\n",
    "print(f\"Variance explained by PC2: {pca.explained_variance_ratio_[1]:.4f}\")\n",
    "print(f\"Total variance explained: {sum(pca.explained_variance_ratio_[:2]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1. Pixel Value Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values to [0, 1]\n",
    "x_train_normalized = x_train.astype('float32') / 255.0\n",
    "x_test_normalized = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Plot original vs normalized image\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Original image\n",
    "idx = np.random.randint(0, len(x_train))\n",
    "axes[0].imshow(x_train[idx], cmap='gray')\n",
    "axes[0].set_title(\"Original Image\\nPixel Values: [0-255]\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Normalized image\n",
    "axes[1].imshow(x_train_normalized[idx], cmap='gray')\n",
    "axes[1].set_title(\"Normalized Image\\nPixel Values: [0-1]\")\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Original image pixel range: [{x_train.min()}, {x_train.max()}]\")\n",
    "print(f\"Normalized image pixel range: [{x_train_normalized.min()}, {x_train_normalized.max()}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2. Reshaping for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape data to include channel dimension for CNN\n",
    "x_train_cnn = x_train_normalized.reshape(-1, 28, 28, 1)\n",
    "x_test_cnn = x_test_normalized.reshape(-1, 28, 28, 1)\n",
    "\n",
    "print(f\"Original shape: {x_train_normalized.shape}\")\n",
    "print(f\"Reshaped for CNN: {x_train_cnn.shape}\")\n",
    "\n",
    "# Visualize transformation (it looks the same but has different shape)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.imshow(x_train_cnn[0, :, :, 0], cmap='gray')\n",
    "ax.set_title(f\"Sample Image\\nShape: {x_train_cnn[0].shape}\")\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3. One-Hot Encoding Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices (one-hot encoding)\n",
    "y_train_categorical = to_categorical(y_train, 10)\n",
    "y_test_categorical = to_categorical(y_test, 10)\n",
    "\n",
    "# Display the original vs one-hot encoded labels\n",
    "idx = 42  # Sample index\n",
    "print(f\"Original label: {y_train[idx]}\")\n",
    "print(f\"One-hot encoded label: {y_train_categorical[idx]}\")\n",
    "print(f\"Decoded from one-hot: {np.argmax(y_train_categorical[idx])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Data Splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1. Create Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Split training data into training and validation sets\n",
    "val_split = 0.1\n",
    "random_seed = 42\n",
    "\n",
    "# Create random indices for splitting\n",
    "np.random.seed(random_seed)\n",
    "indices = np.random.permutation(len(x_train_cnn))\n",
    "val_size = int(len(x_train_cnn) * val_split)\n",
    "train_indices = indices[val_size:]\n",
    "val_indices = indices[:val_size]\n",
    "\n",
    "# Create validation set\n",
    "x_val = x_train_cnn[val_indices]\n",
    "y_val = y_train_categorical[val_indices]\n",
    "\n",
    "# Update training set\n",
    "x_train_final = x_train_cnn[train_indices]\n",
    "y_train_final = y_train_categorical[train_indices]\n",
    "\n",
    "print(f\"Training set: {x_train_final.shape[0]} samples\")\n",
    "print(f\"Validation set: {x_val.shape[0]} samples\")\n",
    "print(f\"Test set: {x_test_cnn.shape[0]} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2. Verify Class Distribution After Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Ensure class balance is preserved in splits\n",
    "train_dist = np.sum(y_train_final, axis=0)\n",
    "val_dist = np.sum(y_val, axis=0)\n",
    "test_dist = np.sum(y_test_categorical, axis=0)\n",
    "\n",
    "# Convert to percentages\n",
    "train_pct = train_dist / np.sum(train_dist) * 100\n",
    "val_pct = val_dist / np.sum(val_dist) * 100\n",
    "test_pct = test_dist / np.sum(test_dist) * 100\n",
    "\n",
    "# Create dataframe for comparison\n",
    "dist_df = pd.DataFrame({\n",
    "    'Training Set (%)': train_pct,\n",
    "    'Validation Set (%)': val_pct,\n",
    "    'Test Set (%)': test_pct\n",
    "}, index=[f'Digit {i}' for i in range(10)])\n",
    "\n",
    "print(\"Class distribution across datasets:\")\n",
    "print(dist_df)\n",
    "\n",
    "# Visualize distribution comparison\n",
    "dist_df.plot(kind='bar', figsize=(14, 7))\n",
    "plt.title('Class Distribution Comparison Across Datasets', fontsize=14)\n",
    "plt.xlabel('Digit Class', fontsize=12)\n",
    "plt.ylabel('Percentage (%)', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Sample Batch Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1. Create and Visualize a Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a small batch of data\n",
    "batch_size = 64\n",
    "batch_indices = np.random.choice(len(x_train_final), batch_size, replace=False)\n",
    "x_batch = x_train_final[batch_indices]\n",
    "y_batch = y_train_final[batch_indices]\n",
    "\n",
    "# Visualize the batch\n",
    "fig, axes = plt.subplots(8, 8, figsize=(12, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(batch_size):\n",
    "    axes[i].imshow(x_batch[i, :, :, 0], cmap='gray')\n",
    "    digit = np.argmax(y_batch[i])\n",
    "    axes[i].set_title(f\"{digit}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Sample Training Batch\", y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Data Augmentation Preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.1. Visualize Image Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Preview data augmentation techniques\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create a data generator with augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Select a single image for demonstration\n",
    "img = x_train_final[0]\n",
    "img = img.reshape((1,) + img.shape)  # reshape for generator\n",
    "\n",
    "# Generate augmented images\n",
    "augmented_images = [img[0]]  # Start with original\n",
    "for i, batch in enumerate(datagen.flow(img, batch_size=1)):\n",
    "    augmented_images.append(batch[0])\n",
    "    if i >= 8:  # Generate 8 augmented images\n",
    "        break\n",
    "\n",
    "# Visualize original and augmented images\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, img in enumerate(augmented_images):\n",
    "    axes[i].imshow(img[:, :, 0], cmap='gray')\n",
    "    if i == 0:\n",
    "        axes[i].set_title(\"Original\")\n",
    "    else:\n",
    "        axes[i].set_title(f\"Augmented #{i}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"Data Augmentation Examples\", y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Summary and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1. Dataset Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a summary table of dataset characteristics\n",
    "summary_data = {\n",
    "    'Description': [\n",
    "        'Dataset Name', \n",
    "        'Number of Training Examples',\n",
    "        'Number of Test Examples',\n",
    "        'Image Dimensions',\n",
    "        'Number of Classes',\n",
    "        'Class Distribution',\n",
    "        'Pixel Value Range (Original)',\n",
    "        'Pixel Value Range (Normalized)'\n",
    "    ],\n",
    "    'Value': [\n",
    "        'MNIST Handwritten Digits',\n",
    "        f'{len(x_train):,}',\n",
    "        f'{len(x_test):,}',\n",
    "        '28x28 grayscale (28x28x1 for CNN)',\n",
    "        '10 (digits 0-9)',\n",
    "        'Approximately balanced',\n",
    "        f'[{x_train.min()}, {x_train.max()}]',\n",
    "        '[0.0, 1.0]'\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2. Preprocessing Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a summary of preprocessing steps\n",
    "preprocess_steps = {\n",
    "    'Step': [\n",
    "        'Normalization', \n",
    "        'Reshaping',\n",
    "        'Label Encoding',\n",
    "        'Data Splitting'\n",
    "    ],\n",
    "    'Description': [\n",
    "        'Scale pixel values from [0-255] to [0-1]',\n",
    "        'Add channel dimension: (samples, 28, 28) â†’ (samples, 28, 28, 1)',\n",
    "        'Convert class labels to one-hot encoded vectors',\n",
    "        'Split training data into training (90%) and validation (10%) sets'\n",
    "    ],\n",
    "    'Purpose': [\n",
    "        'Improves training stability and convergence',\n",
    "        'Required format for CNN input layers',\n",
    "        'Required format for categorical cross-entropy loss',\n",
    "        'Allows monitoring of model performance during training'\n",
    "    ]\n",
    "}\n",
    "\n",
    "preprocess_df = pd.DataFrame(preprocess_steps)\n",
    "preprocess_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.1. Preparation for Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save preprocessed data for model training\n",
    "if not os.path.exists('data/mnist'):\n",
    "    os.makedirs('data/mnist')\n",
    "\n",
    "np.save('data/mnist/x_train.npy', x_train_final)\n",
    "np.save('data/mnist/y_train.npy', y_train_final)\n",
    "np.save('data/mnist/x_val.npy', x_val)\n",
    "np.save('data/mnist/y_val.npy', y_val)\n",
    "np.save('data/mnist/x_test.npy', x_test_cnn)\n",
    "np.save('data/mnist/y_test.npy', y_test_categorical)\n",
    "\n",
    "print(\"Preprocessed data saved to data/mnist/\")\n",
    "print(\"Ready for model building!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14.2. Dataset Overview Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create a final visualization of the dataset\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Visualization 1: Sample digits\n",
    "ax1 = plt.subplot2grid((2, 3), (0, 0))\n",
    "sample_idx = np.random.randint(0, len(x_train))\n",
    "ax1.imshow(x_train[sample_idx], cmap='gray')\n",
    "ax1.set_title(f\"Sample Digit: {y_train[sample_idx]}\")\n",
    "ax1.axis('off')\n",
    "\n",
    "# Visualization 2: Average digits\n",
    "ax2 = plt.subplot2grid((2, 3), (0, 1), colspan=2)\n",
    "ax2.imshow(np.hstack([avg_digits[i] for i in range(10)]), cmap='viridis')\n",
    "ax2.set_title(\"Average Digit Images (0-9)\")\n",
    "ax2.axis('off')\n",
    "\n",
    "# Visualization 3: Class distribution\n",
    "ax3 = plt.subplot2grid((2, 3), (1, 0), colspan=2)\n",
    "ax3.bar(range(10), counts, color='skyblue')\n",
    "ax3.set_title(\"Class Distribution\")\n",
    "ax3.set_xlabel(\"Digit Class\")\n",
    "ax3.set_ylabel(\"Count\")\n",
    "ax3.set_xticks(range(10))\n",
    "\n",
    "# Visualization 4: Pixel intensity distribution\n",
    "ax4 = plt.subplot2grid((2, 3), (1, 2))\n",
    "ax4.hist(pixel_values, bins=20, color='skyblue')\n",
    "ax4.set_title(\"Pixel Distribution\")\n",
    "ax4.set_xlabel(\"Pixel Value\")\n",
    "ax4.set_ylabel(\"Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.suptitle(\"MNIST Dataset Overview\", y=1.02, fontsize=16)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
